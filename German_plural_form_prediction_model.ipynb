{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN4PFVd_QTVU",
        "outputId": "10ef0a21-3146-4dbc-c0b5-3a574b662206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "geQZnuiTsl5n"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writ_data = []\n",
        "phon_data = []\n",
        "filepath = '/content/drive/MyDrive/phonemized_list_shuffled_no_cedilla'\n",
        "with open(filepath, 'r') as f0:\n",
        "  for line in f0:\n",
        "    parts = line.split()\n",
        "    #written form of words\n",
        "    writ_singular = parts[0]\n",
        "    writ_plural = parts[1]\n",
        "    writ_data.append((writ_singular, writ_plural))\n",
        "    #phonemized form of words\n",
        "    phon_singular = parts[2]\n",
        "    phon_plural = parts[3]\n",
        "    phon_data.append((phon_singular, phon_plural))"
      ],
      "metadata": {
        "id": "Gf_hc8vcz5Qm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#randomly selecting writ_data to create a subset\n",
        "writ_data = random.sample(writ_data, 8500)\n",
        "\n",
        "spellings = set(' '.join([writ_plural for _, writ_plural in writ_data]))\n",
        "spellings.add('post')\n",
        "spelling_to_idx = {spelling: idx for idx, spelling in enumerate(spellings)}\n",
        "\n",
        "def writ_encode_sequences(writ_sequences, spelling_to_idx):\n",
        "    writ_encoded_seqs = []\n",
        "    for writ_sequence in writ_sequences:\n",
        "        writ_encoded_seq = [spelling_to_idx[spelling] for spelling in writ_sequence]\n",
        "        writ_encoded_seqs.append(writ_encoded_seq)\n",
        "    return writ_encoded_seqs"
      ],
      "metadata": {
        "id": "MxOORvCy2681"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#randomly selecting phon_data to create a subset\n",
        "phon_data = random.sample(phon_data, 8500)\n",
        "\n",
        "phonemes = set(' '.join([phon_plural for _, phon_plural in phon_data]))\n",
        "phonemes.add('post')\n",
        "phoneme_to_idx = {phoneme: idx for idx, phoneme in enumerate(phonemes)}\n",
        "\n",
        "def phon_encode_sequences(phon_sequences, phoneme_to_idx):\n",
        "    phon_encoded_seqs = []\n",
        "    for phon_sequence in phon_sequences:\n",
        "        phon_encoded_seq = [phoneme_to_idx[phoneme] for phoneme in phon_sequence]\n",
        "        phon_encoded_seqs.append(phon_encoded_seq)\n",
        "    return phon_encoded_seqs"
      ],
      "metadata": {
        "id": "qwH2gg2s3mWh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making writ_train and writ_test datasets\n",
        "writ_train_data, writ_test_data = train_test_split(writ_data, train_size=0.8, test_size=0.2, shuffle=True)\n",
        "\n",
        "#and seperate for singular/plural\n",
        "writ_trainData_singular = [writ_singular for writ_singular, _ in writ_train_data]\n",
        "writ_trainData_plural = [writ_plural for _, writ_plural in writ_train_data]\n",
        "writ_testData_singular = [writ_singular for writ_singular, _ in writ_test_data]\n",
        "writ_testData_plural = [writ_plural for _, writ_plural in writ_test_data]\n",
        "\n",
        "writ_num_class = len(np.unique(writ_testData_plural)) + 2\n",
        "writ_train_max_seq_len = max(len(seq) for seq in writ_trainData_singular + writ_trainData_plural)\n",
        "writ_test_max_seq_len = max(len(seq) for seq in writ_testData_singular + writ_testData_plural)"
      ],
      "metadata": {
        "id": "6c936m9o4STl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making phon_train and phon_test datasets\n",
        "phon_train_data, phon_test_data = train_test_split(phon_data, train_size=0.8, test_size=0.2, shuffle=True)\n",
        "\n",
        "#and seperate for singular/plural\n",
        "phon_trainData_singular = [phon_singular for phon_singular, _ in phon_train_data]\n",
        "phon_trainData_plural = [phon_plural for _, phon_plural in phon_train_data]\n",
        "phon_testData_singular = [phon_singular for phon_singular, _ in phon_test_data]\n",
        "phon_testData_plural = [phon_plural for _, phon_plural in phon_test_data]\n",
        "\n",
        "phon_num_class = len(np.unique(phon_testData_plural)) + 2\n",
        "phon_train_max_seq_len = max(len(seq) for seq in phon_trainData_singular + phon_trainData_plural)\n",
        "phon_test_max_seq_len = max(len(seq) for seq in phon_testData_singular + phon_testData_plural)"
      ],
      "metadata": {
        "id": "20ZrEG4w4U7j"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding process for writ_datasets\n",
        "writ_trainData_singular = pad_sequences(writ_encode_sequences(writ_trainData_singular, spelling_to_idx),\n",
        "                                   maxlen = writ_train_max_seq_len, padding = 'post')\n",
        "writ_trainData_plural = pad_sequences(writ_encode_sequences(writ_trainData_plural, spelling_to_idx),\n",
        "                                   maxlen = writ_train_max_seq_len, padding = 'post')\n",
        "writ_trainData_plural_encoded = to_categorical(writ_trainData_plural, writ_num_class)\n",
        "\n",
        "writ_testData_singular = pad_sequences(writ_encode_sequences(writ_testData_singular, spelling_to_idx),\n",
        "                                   maxlen = writ_test_max_seq_len, padding = 'post')\n",
        "writ_testData_plural = pad_sequences(writ_encode_sequences(writ_testData_plural, spelling_to_idx),\n",
        "                                   maxlen = writ_test_max_seq_len, padding = 'post')\n",
        "writ_testData_plural_encoded = to_categorical(writ_testData_plural, writ_num_class)"
      ],
      "metadata": {
        "id": "L3iz8hmo4207"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding process for phon_datasets\n",
        "phon_trainData_singular = pad_sequences(phon_encode_sequences(phon_trainData_singular, phoneme_to_idx),\n",
        "                                   maxlen = phon_train_max_seq_len, padding = 'post')\n",
        "phon_trainData_plural = pad_sequences(phon_encode_sequences(phon_trainData_plural, phoneme_to_idx),\n",
        "                                   maxlen = phon_train_max_seq_len, padding = 'post')\n",
        "phon_trainData_plural_encoded = to_categorical(phon_trainData_plural, phon_num_class)\n",
        "\n",
        "phon_testData_singular = pad_sequences(phon_encode_sequences(phon_testData_singular, phoneme_to_idx),\n",
        "                                   maxlen = phon_test_max_seq_len, padding = 'post')\n",
        "phon_testData_plural = pad_sequences(phon_encode_sequences(phon_testData_plural, phoneme_to_idx),\n",
        "                                   maxlen = phon_test_max_seq_len, padding = 'post')\n",
        "phon_testData_plural_encoded = to_categorical(phon_testData_plural, phon_num_class)"
      ],
      "metadata": {
        "id": "vysvWpK143kD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating model for writ_datasets\n",
        "writ_model = Sequential()\n",
        "writ_embedding_dim = 50\n",
        "writ_input_dim = len(spellings)\n",
        "writ_model.add(Embedding(writ_input_dim, writ_embedding_dim))\n",
        "writ_model.add(Dense(128, activation='relu'))\n",
        "writ_model.add(Dense(writ_num_class, activation='softmax'))\n",
        "writ_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bpbW0D1Q5u8P"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating model for phon_datasets\n",
        "phon_model = Sequential()\n",
        "phon_embedding_dim = 50\n",
        "phon_input_dim = len(phonemes)\n",
        "phon_model.add(Embedding(phon_input_dim, phon_embedding_dim))\n",
        "phon_model.add(Dense(128, activation='relu'))\n",
        "phon_model.add(Dense(phon_num_class, activation='softmax'))\n",
        "phon_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "m0LWAbhB5vKD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writ_model.fit(writ_trainData_singular, writ_trainData_plural_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "#writ_trainData\n",
        "writ_train_loss, writ_trainData_accuracy = writ_model.evaluate(writ_trainData_singular, writ_trainData_plural_encoded)\n",
        "print(f\"writ_trainData Accuracy: {writ_trainData_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuHp3QGy6IBp",
        "outputId": "ab552aa5-6ac1-4f2c-fcbd-1aff53e52f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8714 - loss: 3.6009"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#writ_testData\n",
        "writ_test_loss, writ_testData_accuracy = writ_model.evaluate(writ_testData_singular, writ_testData_plural_encoded)\n",
        "print(f\"writ_testData Accuracy: {writ_testData_accuracy}\")"
      ],
      "metadata": {
        "id": "Z8TK2ZG16TM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "phon_model.fit(phon_trainData_singular, phon_trainData_plural_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "#phon_trainData\n",
        "phon_train_loss, phon_trainData_accuracy = phon_model.evaluate(phon_trainData_singular, phon_trainData_plural_encoded)\n",
        "print(f\"phon_trainData Accuracy: {phon_trainData_accuracy}\")"
      ],
      "metadata": {
        "id": "itutNtLZ6jUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#phon_testData\n",
        "phon_test_loss, phon_testData_accuracy = phon_model.evaluate(phon_testData_singular, phon_testData_plural_encoded)\n",
        "print(f\"phon_testData Accuracy: {phon_testData_accuracy}\")"
      ],
      "metadata": {
        "id": "ONQWQThB6tW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}